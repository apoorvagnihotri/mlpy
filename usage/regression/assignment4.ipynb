{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "dirr = \"../../src\"\n",
    "if dirr not in sys.path:\n",
    "    sys.path.append(dirr)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import utils as helper\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2\n",
    "Custom functions for differnt ways to calculate theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apoorv/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.72727271, 0.18949772, 0.0125958 , 0.5       , 0.42014057,\n",
       "        0.72395946],\n",
       "       [0.27272729, 0.29680365, 0.07252509, 0.5       , 0.40087252,\n",
       "        0.68837611],\n",
       "       [0.72727271, 0.58447489, 0.69552341, 0.        , 0.19619486,\n",
       "        0.24088851]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading data\n",
    "data_loc = \"../../data/real_estate/dataset.xlsx\"\n",
    "data = pd.read_excel(data_loc)\n",
    "X = data.iloc[:, 1:-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Normalizing the data\n",
    "scaler = MinMaxScaler()\n",
    "X[X.columns] = scaler.fit_transform(X[X.columns])\n",
    "tupl = train_test_split(X.values, y.values, test_size = .3)\n",
    "X_train, X_test, y_train, y_test = tupl\n",
    "X_train[:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalEquationRidgeRegression:\n",
      " [ 30.8772563    4.02902254 -10.00324397 -28.90024718  11.62381309\n",
      "  18.16719681   1.08461451]\n"
     ]
    }
   ],
   "source": [
    "from lregress import normalEquationRidgeRegression\n",
    "theta = normalEquationRidgeRegression(X_train, y_train, lmbd=0.1)\n",
    "print (\"normalEquationRidgeRegression:\\n\", theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgdRegression:\n",
      " [10.73818571 10.53775786 11.3733753  11.39333645 11.06786246 10.83888066\n",
      " 10.98884252]\n"
     ]
    }
   ],
   "source": [
    "# from lregress import normalEquationRidgeRegression\n",
    "# print(type(y_train))\n",
    "# for i in range(len(y_train)):\n",
    "#     print (y_train[i])\n",
    "theta = sgdRegression(X_train, y_train, alpha = 0.01, it=100)\n",
    "print (\"sgdRegression:\\n\", theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import prepend_ones_col\n",
    "def sgdRegression(X, y, alpha = 0.001, it=100):\n",
    "    X_new = prepend_ones_col(X)\n",
    "    n, m = X_new.shape\n",
    "    th = np.random.rand(m)\n",
    "    for i in range(it):\n",
    "        for j in range(n):\n",
    "            yhat = (X_new[j, :] * th).sum()\n",
    "            e = y[j]-yhat\n",
    "            weighted_e = X_new[j, :] * e\n",
    "            sumz = weighted_e.sum()\n",
    "            th = th + (2*alpha*(sumz))\n",
    "    return th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Q5\n",
    "Using sklearn's RIDGE and LASSO modules after normalizing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE error obtained is:  10.809957718336143\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross(dTrain, depths, num_valid):\n",
    "    folds = make_folds(dTrain, num_valid)\n",
    "    passed_folds = folds[:-1] # holding out test\n",
    "    k = best_k(passed_folds, depths)\n",
    "    acc = 0\n",
    "    curr_fold_train = folds[:-1]\n",
    "    curr_fold_test = folds[-1]\n",
    "    linear_reg = Ridge(alpha=k)\n",
    "    linear_reg.fit(curr_fold_train.iloc[:, :-1], curr_fold_train.iloc[:, -1])\n",
    "    my_preds = np.squeeze(mydt.predict(curr_fold_test.iloc[:, :-1]).values)\n",
    "    true = curr_fold_test.iloc[:, -1].values\n",
    "    my_acc = ((true == my_preds).sum())/curr_fold_test.shape[0]\n",
    "    acc += my_acc/num_valid\n",
    "    return {\"depth\": k, \"acc\": acc}   \n",
    "\n",
    "def make_folds(dTrain, num_valid):\n",
    "    '''Make a number of folds with diven pd'''\n",
    "    train = shuffle(dTrain)\n",
    "    last = train.shape[0]\n",
    "    folds = []\n",
    "    for i in range(num_valid):\n",
    "        start = i*int(last/num_valid)\n",
    "        end = (i+1)*int(last/num_valid)\n",
    "        if end >= last:\n",
    "            end = -1\n",
    "        folds.append(train.iloc[start:end, :])\n",
    "    return folds\n",
    "\n",
    "def best_k(folds, depths):\n",
    "    '''return depth that maximizes the avg accuracy'''\n",
    "    num_valid = len(folds)\n",
    "    acc = {}\n",
    "    for i in range(num_valid):\n",
    "        curr_fold_train = [x for j,x in enumerate(folds) if j!=i] \n",
    "        curr_fold_validation = folds[i]\n",
    "        curr_fold_train = pd.concat(curr_fold_train)\n",
    "        for k in depths:\n",
    "            linear_reg = Ridge(alpha=k)\n",
    "            linear_reg.fit(curr_fold_train.iloc[:, :-1], curr_fold_train.iloc[:, -1])\n",
    "            my_preds = np.squeeze(mydt.predict(curr_fold_validation.iloc[:, :-1]).values)\n",
    "            true = curr_fold_validation.iloc[:, -1].values\n",
    "            my_acc = ((true == my_preds).sum())/curr_fold_validation.shape[0]\n",
    "            if k in acc.keys():\n",
    "                acc[k] += my_acc\n",
    "            else:\n",
    "                acc[k] = my_acc\n",
    "    acc = {k: acc[k]/num_valid for k in acc.keys()}\n",
    "    \n",
    "    x = acc\n",
    "    print (acc) # for showcasing\n",
    "    sorted_by_value = sorted(x.items(), key=lambda kv: kv[1])\n",
    "    return sorted(x[0] for x in sorted_by_value if sorted_by_value[-1][1] == x[1])[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lr = Ridge(alpha=1.0)\n",
    "lr.fit(X_)\n",
    "\n",
    "def cross_val(master_data, clf, fol=5):\n",
    "    dFull = master_data.copy()\n",
    "    kf = KFold(n_splits=fol, shuffle=True)\n",
    "\n",
    "    train_rmse = {}\n",
    "    val_rmse = {}\n",
    "    for i, (ixTrain, ixVal) in enumerate(kf.split(dFull)):\n",
    "        # combining the folds\n",
    "        fTrain, fVal = dFull.iloc[ixTrain], dFull.iloc[ixVal]\n",
    "        \n",
    "        # training on train and getting predictions on val, and train\n",
    "        clf.fit(fTrain.iloc[:, :-1], fTrain.iloc[:, -1])\n",
    "        y_pred_val = clf.predict(fVal.iloc[:, :-1])\n",
    "        y_pred_train = clf.predict(fTrain.iloc[:, :-1])\n",
    "        \n",
    "        \n",
    "        # getting the rmse values for train and val\n",
    "        r_val = helper.rmse(y_pred_val, y_test_set.values)\n",
    "        r_train = helper.rmse(y_pred_train, fTrain.iloc[:, -1].values)\n",
    "        \n",
    "        \n",
    "        train_rmse[ixTrain] = r_val \n",
    "        val_rmse[ixVal] = r_train\n",
    "        \n",
    "    bst_fea_till_now = list(min(saved_rmse, key=saved_rmse.get))\n",
    "    curr_rmse = saved_rmse[tuple(bst_fea_till_now)]\n",
    "    if (best_rmse > curr_rmse + tol):\n",
    "        saved_fea = bst_fea_till_now\n",
    "        best_rmse = curr_rmse\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    # getting the best set of features, (min rms)\n",
    "    best_feature = dTrain.columns[list(min(saved_rmse, key=saved_rmse.get))]\n",
    "    print(\"Best Feature Set: {}\".format(list(best_feature)))\n",
    "\n",
    "    reg_org = LinearRegression().fit(dTrain.iloc[:, best_feature], dTrain.iloc[:, -1])\n",
    "    y_pred = reg_org.predict(dTest.iloc[:, best_feature])\n",
    "    err = y_pred - dTest.iloc[:, -1].values\n",
    "    rms_err = np.sqrt(np.square(err).sum()/len(y_pred))\n",
    "    print(rms_err)\n",
    "\n",
    "    print(\"Complete Feature Set: {}\".format(list(dTrain.columns)))\n",
    "    reg_op = LinearRegression().fit(dTrain.iloc[:, :-1], dTrain.iloc[:, -1])\n",
    "    y_pred = reg_op.predict(dTest.iloc[:, :-1])\n",
    "    err = y_pred - dTest.iloc[:, -1].values\n",
    "    rms_err = np.sqrt(np.square(err).sum()/len(y_pred))\n",
    "    print(rms_err)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "print(\"The RMSE error obtained is: \", helper.rmse(y_pred, y_test.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,6.15))\n",
    "map_X, map_Y = np.meshgrid(theta0_grid, theta1_grid)\n",
    "ax[0].scatter(x, Y, marker='x', s=40, color='k')\n",
    "contours = ax[1].contour(map_Y, map_X, J_grid, 30)\n",
    "ax[1].clabel(contours)\n",
    "ax[1].scatter([theta0_true]*2,[theta1_true]*2,s=[50,10], color=['k','w'])\n",
    "ax[1].set_xlabel(r'$\\theta_0$')\n",
    "ax[1].set_ylabel(r'$\\theta_1$')\n",
    "ax[1].set_title('Cost function')\n",
    "ax[0].set_xlabel(r'$x$')\n",
    "ax[0].set_ylabel(r'$y$')\n",
    "ax[0].set_title('Data and fit')\n",
    "line, = ax[0].plot([], [], color='r', lw=2,label=r'$\\theta_0 = {:.3f}, \\theta_1 = {:.3f}$'.format(*Theta[0]))\n",
    "def animate(i):\n",
    "   '''ax[0].plot(X, predict(Theta[i], X), color='r', lw=2,\n",
    "              label=r'$\\theta_0 = {:.3f}, \\theta_1 = {:.3f}$'.format(*Theta[i]))'''\n",
    "   #ax[1].scatter(Theta[i][0], Theta[i][1], s=40, lw=0)\n",
    "   z = predict(Theta[i], X)\n",
    "   line.set_data(X[:, 1], z)\n",
    "   ax[1].annotate('', xy=Theta[i], xytext=Theta[i-1],arrowprops={'arrowstyle': '->', 'color': 'r', 'lw': 1}, va='center', ha='center')\n",
    "   #ax[0].plot(X, predict(Theta[i], X), color='r', lw=2,label=r'$\\theta_0 = {:.3f}, \\theta_1 = {:.3f}$'.format(*Theta[i]))\n",
    "   return ax\n",
    "\n",
    "#anim = animation.FuncAnimation(fig, animate, frames=10, interval=20, blit=True)\n",
    "anim = animation.FuncAnimation(fig, animate, frames=1000, interval=20, blit=True)\n",
    "#HTML(anim.to_html5_video())\n",
    "anim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
