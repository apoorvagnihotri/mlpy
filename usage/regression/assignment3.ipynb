{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Plain\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "dirr = \"../../src\"\n",
    "if dirr not in sys.path:\n",
    "    sys.path.append(dirr)\n",
    "%xmode Plain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import utils as helper\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1\n",
    "Link to the [pdf](https://drive.google.com/file/d/1YhLUJuHG-geJgn1pXUl7KHdrrjGvUgQr/view?usp=sharing)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2\n",
    "a) Solution by sk-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[1, 2],\n",
    "     [2, 4],\n",
    "     [3, 6],\n",
    "     [4, 8]]\n",
    "y = [2,3,4,5]\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "# Setting up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.16])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict([[2,4.4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Q2\n",
    "b) Using normal Equations.\n",
    "\n",
    "We get ``LinAlgError`` because the matrix $X.X^{T}$ is singular, therefore inverting such a matrix would fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"<ipython-input-5-b48f167ccf1d>\"\u001b[0m, line \u001b[0;32m2\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    theta = normalEquationRegression(X, y)\n",
      "  File \u001b[0;32m\"../../src\\lregress.py\"\u001b[0m, line \u001b[0;32m10\u001b[0m, in \u001b[0;35mnormalEquationRegression\u001b[0m\n    temp = np.linalg.inv(temp)\n",
      "  File \u001b[0;32m\"D:\\Users\\apoor\\Miniconda3\\envs\\3d\\lib\\site-packages\\numpy\\linalg\\linalg.py\"\u001b[0m, line \u001b[0;32m532\u001b[0m, in \u001b[0;35minv\u001b[0m\n    ainv = _umath_linalg.inv(a, signature=signature, extobj=extobj)\n",
      "\u001b[1;36m  File \u001b[1;32m\"D:\\Users\\apoor\\Miniconda3\\envs\\3d\\lib\\site-packages\\numpy\\linalg\\linalg.py\"\u001b[1;36m, line \u001b[1;32m89\u001b[1;36m, in \u001b[1;35m_raise_linalgerror_singular\u001b[1;36m\u001b[0m\n\u001b[1;33m    raise LinAlgError(\"Singular matrix\")\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m\u001b[1;31m:\u001b[0m Singular matrix\n"
     ]
    }
   ],
   "source": [
    "from lregress import normalEquationRegression\n",
    "theta = normalEquationRegression(X, y)\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sk-learn overcomes this problem by using a different technique to calculate inverses, called [Mooreâ€“Penrose pseudo inverse](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Q3\n",
    "a) Running Sk-learn on real-estate price prediction problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1 transaction date</th>\n",
       "      <th>X2 house age</th>\n",
       "      <th>X3 distance to the nearest MRT station</th>\n",
       "      <th>X4 number of convenience stores</th>\n",
       "      <th>X5 latitude</th>\n",
       "      <th>X6 longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>2012.833333</td>\n",
       "      <td>10.3</td>\n",
       "      <td>211.4473</td>\n",
       "      <td>1</td>\n",
       "      <td>24.97417</td>\n",
       "      <td>121.52999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2013.333333</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1360.1390</td>\n",
       "      <td>1</td>\n",
       "      <td>24.95204</td>\n",
       "      <td>121.54842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2013.083333</td>\n",
       "      <td>38.6</td>\n",
       "      <td>804.6897</td>\n",
       "      <td>4</td>\n",
       "      <td>24.97838</td>\n",
       "      <td>121.53477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2013.416667</td>\n",
       "      <td>35.3</td>\n",
       "      <td>614.1394</td>\n",
       "      <td>7</td>\n",
       "      <td>24.97913</td>\n",
       "      <td>121.53666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2013.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.4296</td>\n",
       "      <td>0</td>\n",
       "      <td>24.97110</td>\n",
       "      <td>121.53170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1 transaction date  X2 house age  \\\n",
       "356          2012.833333          10.3   \n",
       "152          2013.333333          12.0   \n",
       "126          2013.083333          38.6   \n",
       "364          2013.416667          35.3   \n",
       "123          2013.416667           0.0   \n",
       "\n",
       "     X3 distance to the nearest MRT station  X4 number of convenience stores  \\\n",
       "356                                211.4473                                1   \n",
       "152                               1360.1390                                1   \n",
       "126                                804.6897                                4   \n",
       "364                                614.1394                                7   \n",
       "123                                185.4296                                0   \n",
       "\n",
       "     X5 latitude  X6 longitude  \n",
       "356     24.97417     121.52999  \n",
       "152     24.95204     121.54842  \n",
       "126     24.97838     121.53477  \n",
       "364     24.97913     121.53666  \n",
       "123     24.97110     121.53170  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loc = \"../../data/real_estate/dataset.xlsx\"\n",
    "data = pd.read_excel(data_loc)\n",
    "X = data.iloc[:, 1:-1]\n",
    "y = data.iloc[:, -1]\n",
    "tupl = train_test_split(X, y)\n",
    "X_train, X_test, y_train, y_test = tupl\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(pred, true):\n",
    "    return np.sqrt(np.mean((pred-true)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE error obtained is:  7.137472504145238\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print(\"The RMSE error obtained is: \", rmse(y_pred, y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.90716451e+00 -2.60249095e-01 -4.86518419e-03  9.78288202e-01\n",
      "  2.20094114e+02 -1.65014835e+01]\n",
      "-15337.93656328878\n"
     ]
    }
   ],
   "source": [
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Q3\n",
    "b) To assume that the co-efficients learnt signify the importance of the feature is wrong. This can be shown by thinking of a example where on of the feature measures some quantities in ``centimeters`` and the same feature is converted to ``inches`` in the next curve fitting. Since we already know the importance of the feature would not change by the unit it is measured in but the co-efficients would get changed. Here by taking a feature in a different unit, the importance of the feature can be decreased (stated in the question) is a contradiction as clearly importance of a feature is not dependent on the unit it is measured. There for the coefficients don't tell us anything about the importance of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coeffs learnt are the following: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 5.90716451e+00, -2.60249095e-01, -4.86518419e-03,  9.78288202e-01,\n",
       "        2.20094114e+02, -1.65014835e+01])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_ = lr.coef_\n",
    "print(\"The coeffs learnt are the following: \")\n",
    "coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Q3\n",
    "c) Scaling the numerical columns of the Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1 transaction date</th>\n",
       "      <th>X2 house age</th>\n",
       "      <th>X3 distance to the nearest MRT station</th>\n",
       "      <th>X4 number of convenience stores</th>\n",
       "      <th>X5 latitude</th>\n",
       "      <th>X6 longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.591324</td>\n",
       "      <td>0.695523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196195</td>\n",
       "      <td>0.240889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.420091</td>\n",
       "      <td>0.410167</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.355793</td>\n",
       "      <td>0.374596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.278539</td>\n",
       "      <td>0.206780</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.242002</td>\n",
       "      <td>0.807526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1 transaction date  X2 house age  \\\n",
       "30              0.909091      0.591324   \n",
       "352             0.181818      0.420091   \n",
       "107             0.727273      0.278539   \n",
       "\n",
       "     X3 distance to the nearest MRT station  X4 number of convenience stores  \\\n",
       "30                                 0.695523                              0.0   \n",
       "352                                0.410167                              0.3   \n",
       "107                                0.206780                              0.1   \n",
       "\n",
       "     X5 latitude  X6 longitude  \n",
       "30      0.196195      0.240889  \n",
       "352     0.355793      0.374596  \n",
       "107     0.242002      0.807526  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaling the features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X[X.columns] = scaler.fit_transform(X[X.columns])\n",
    "tupl = train_test_split(X, y)\n",
    "X_train, X_test, y_train, y_test = tupl\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coeffs learnt are the following: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  5.27239032, -10.31532535, -26.20952979,  14.69108618,\n",
       "        14.25121949,   0.52711944])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "coef_ = lr.coef_\n",
    "print(\"The coeffs learnt are the following: \")\n",
    "coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Q3\n",
    "c)\n",
    "Coefficients learnt on the normalized data still don't ######### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Q3\n",
    "d) Distribution of the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred-y_test, bins=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution is mostly centered at 0 with a look of a gaussian (Not sure if it should be, mathematically). We see a noisy sample in our data though, the point that has a error of nearly -75.\n",
    "\n",
    "One thing that I feel is that if we remove the outlier, the data would be much better fitted. I am able to guess this as we know that our error function is Root Mean Squared, which takes the square of the error, and a larger error would have a much larger affect on our qudratic error function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3\n",
    "e) 5 Cross-Validation for hyperparameter selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cross(dTrain, depths, num_valid):\n",
    "    folds = make_folds(dTrain, num_valid)\n",
    "    # holding out test\n",
    "    passed_folds = folds[:-1]\n",
    "    k = best_k(passed_folds, depths)\n",
    "    acc = 0\n",
    "    for i in range(num_valid):\n",
    "        curr_fold_train = [x for j,x in enumerate(folds) if j!=i] \n",
    "        curr_fold_test = folds[i]\n",
    "        curr_fold_train = pd.concat(curr_fold_train)\n",
    "        mydt = LinearRegression()\n",
    "        mydt.fit(curr_fold_train.iloc[:, :-1], curr_fold_train.iloc[:, -1])\n",
    "        my_preds = np.squeeze(mydt.predict(curr_fold_test.iloc[:, :-1]).values)\n",
    "        true = curr_fold_test.iloc[:, -1].values\n",
    "        my_acc = ((true == my_preds).sum())/curr_fold_test.shape[0]\n",
    "        acc += my_acc/num_valid\n",
    "    return {\"depth\": k, \"acc\": acc}   \n",
    "\n",
    "def make_folds(dTrain, num_valid):\n",
    "    '''Make a number of folds with diven pd'''\n",
    "    train = shuffle(dTrain)\n",
    "    last = train.shape[0]\n",
    "    folds = []\n",
    "    for i in range(num_valid):\n",
    "        start = i*int(last/num_valid)\n",
    "        end = (i+1)*int(last/num_valid)\n",
    "        if end >= last:\n",
    "            end = -1\n",
    "        folds.append(train.iloc[start:end, :])\n",
    "    return folds\n",
    "\n",
    "def best_k(folds, depths):\n",
    "    '''return depth that maximizes the avg accuracy'''\n",
    "    num_valid = len(folds)\n",
    "    acc = {}\n",
    "    for i in range(num_valid):\n",
    "        curr_fold_train = [x for j,x in enumerate(folds) if j!=i] \n",
    "        curr_fold_validation = folds[i]\n",
    "        curr_fold_train = pd.concat(curr_fold_train)\n",
    "        for k in depths:\n",
    "            mydt = LinearRegression()\n",
    "            mydt.fit(curr_fold_train.iloc[:, :-1], curr_fold_train.iloc[:, -1])\n",
    "            my_preds = mydt.predict(curr_fold_validation.iloc[:, :-1])\n",
    "            true = curr_fold_validation.iloc[:, -1]\n",
    "            true = true.values\n",
    "            my_preds = np.squeeze(my_preds.values)\n",
    "            assert (true.shape == my_preds.shape)\n",
    "            my_acc = ((true == my_preds).sum())/curr_fold_validation.shape[0]\n",
    "            if k in acc.keys():\n",
    "                acc[k] += my_acc\n",
    "            else:\n",
    "                acc[k] = my_acc\n",
    "    acc = {k: acc[k]/num_valid for k in acc.keys()}\n",
    "    \n",
    "    x = acc\n",
    "    print (acc) # for showcasing\n",
    "    sorted_by_value = sorted(x.items(), key=lambda kv: kv[1])\n",
    "    return sorted(x[0] for x in sorted_by_value if sorted_by_value[-1][1] == x[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Q4\n",
    "[Link](https://gist.github.com/k0pch4/4ae7c4929558cfa2c54c9517466b03e6#file-lregress-py) to all the functions below.\n",
    "\n",
    "a) ``normalEquationRegression(X, y)`` takes in ``X`` and ``y`` and returns a vector ``Theta=[theta0, ..., thetad]`` of dimention 1 more than the number of features in ``X``.\n",
    "\n",
    "b) ``gradientDescentRegression(X, y, alpha=0.1)`` uses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 31.01721261,   5.27239032, -10.31532535, -26.20952979,\n",
       "        14.69108618,  14.25121949,   0.52711944])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lregress import normalEquationRegression\n",
    "normalEquationRegression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 28.84155114,   5.23773521, -10.28164931, -23.96792378,\n",
       "        14.94653925,  14.941082  ,   2.68577124])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lregress import gradientDescentRegression\n",
    "gradientDescentRegression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating some data\n",
    "x = np.arange(0, 20.1, 0.1)\n",
    "np.random.seed(0)\n",
    "y = 1*x**5 + 3*x**4 - 100*x**3 + \\\n",
    "    8*x**2 -300*x - 1e5 + \\\n",
    "    np.random.randn(len(x))*1e5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Using normal Equations\n",
    "link to [pdf](https://drive.google.com/file/d/1xoMWRFT8beyL0IEr9pltqCyD1svStdA8/view?usp=sharing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
